{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNS4AKQObrQVgQtYl/UOGuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elmir22/Data-science-ML-models-/blob/main/shakespear_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URpVqcTNywGg",
        "outputId": "2027387d-d940-487f-cc6f-88ff89a26160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "shakespear_url = \"https://homl.info/shakespeare\"\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespear_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shakespeare_text[:80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84-gR1N4zLqV",
        "outputId": "81b5568b-ba4b-40e2-a9f2-4e84d0e753e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join(sorted(set(shakespeare_text.lower())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EgKWRcaUzV7A",
        "outputId": "263f5e1b-653e-4569-a144-c1dac4d72df4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                   standardize='lower')\n",
        "\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "encoded = text_vec_layer([shakespeare_text])[0]"
      ],
      "metadata": {
        "id": "1Mzi8pU4zaHd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQTefG7j14H3",
        "outputId": "f83ecb31-f400-4b24-e46f-751749a11286"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOgSLIu61KXL",
        "outputId": "43dfe520-cbc4-493e-8dba-8de4765ddd18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " ' ',\n",
              " 'e',\n",
              " 't',\n",
              " 'o',\n",
              " 'a',\n",
              " 'i',\n",
              " 'h',\n",
              " 's',\n",
              " 'r',\n",
              " 'n',\n",
              " '\\n',\n",
              " 'l',\n",
              " 'd',\n",
              " 'u',\n",
              " 'm',\n",
              " 'y',\n",
              " 'w',\n",
              " ',',\n",
              " 'c',\n",
              " 'f',\n",
              " 'g',\n",
              " 'b',\n",
              " 'p',\n",
              " ':',\n",
              " 'k',\n",
              " 'v',\n",
              " '.',\n",
              " \"'\",\n",
              " ';',\n",
              " '?',\n",
              " '!',\n",
              " '-',\n",
              " 'j',\n",
              " 'q',\n",
              " 'x',\n",
              " 'z',\n",
              " '3',\n",
              " '&',\n",
              " '$']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded -= 2\n",
        "n_tokens = text_vec_layer.vocabulary_size()-2\n",
        "dataset_size = len(encoded) #\n",
        "dataset_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLMDQz1o0mhi",
        "outputId": "d1d888ff-64a5-46b3-9db5-c53983ff9b46"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TbR9V7x1YF_",
        "outputId": "e243c491-cf4c-4db3-a35e-e17e633a4836"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "  ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "  ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
        "  ds = ds.flat_map(lambda window: window.batch(length + 1))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(100_000, seed=seed)\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds.map(lambda window: (window[:,:-1], window[:,1:])).prefetch(1)\n",
        ""
      ],
      "metadata": {
        "id": "Lc298C8L2DoX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(to_dataset(tf.range(10),3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV5yd4QR24eZ",
        "outputId": "0eda70fb-9e5f-49db-9b0c-aff7633e8375"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<tf.Tensor: shape=(7, 3), dtype=int32, numpy=\n",
              "  array([[0, 1, 2],\n",
              "         [1, 2, 3],\n",
              "         [2, 3, 4],\n",
              "         [3, 4, 5],\n",
              "         [4, 5, 6],\n",
              "         [5, 6, 7],\n",
              "         [6, 7, 8]], dtype=int32)>,\n",
              "  <tf.Tensor: shape=(7, 3), dtype=int32, numpy=\n",
              "  array([[1, 2, 3],\n",
              "         [2, 3, 4],\n",
              "         [3, 4, 5],\n",
              "         [4, 5, 6],\n",
              "         [5, 6, 7],\n",
              "         [6, 7, 8],\n",
              "         [7, 8, 9]], dtype=int32)>)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = 100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed=42)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
        "test_set = to_dataset(encoded[1_060_000:], length=length)"
      ],
      "metadata": {
        "id": "ZsXUh43H4Tib"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building AND Trainning the Char_ RNN Mode"
      ],
      "metadata": {
        "id": "X3uR0KUS5cZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_mode\", monitor=\"val_accuracy\", save_best_only=True)\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=3, callbacks=[model_ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdi692PC5nsg",
        "outputId": "ad0653bc-6592-4041-b2de-87044f1d3280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "31247/31247 [==============================] - 455s 14ms/step - loss: 1.3931 - accuracy: 0.5735 - val_loss: 1.5905 - val_accuracy: 0.5371\n",
            "Epoch 2/3\n",
            "31247/31247 [==============================] - 519s 16ms/step - loss: 1.2932 - accuracy: 0.5970 - val_loss: 1.5749 - val_accuracy: 0.5423\n",
            "Epoch 3/3\n",
            " 3336/31247 [==>...........................] - ETA: 6:24 - loss: 1.2678 - accuracy: 0.6016"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shakespare_model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda X: X-2),\n",
        "    model\n",
        "])"
      ],
      "metadata": {
        "id": "P0EzwkkC7Njl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extra code – downloads a pretrained model\n",
        "from pathlib import Path\n",
        "url = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\n",
        "\n",
        "path = tf.keras.utils.get_file(\"shakespeare_model.tgz\", url, extract=True)\n",
        "model_path = Path(path).with_name(\"shakespeare_model\")\n",
        "shakespeare_model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "GAt4mSr3730g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0,-1]\n",
        "y_pred = tf.argmax(y_proba)\n",
        "text_vec_layer.get_vocabulary()[y_pred+2]"
      ],
      "metadata": {
        "id": "ExKkmeL376e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#generating fake shakespearean text"
      ],
      "metadata": {
        "id": "uTG1B_hG80vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = tf.math.log([[0.5, 0.4,0.1]]) # probas = 50% 40% 10%\n",
        "tf.random.set_seed(42)\n",
        "tf.random.categorical(log_probas, num_samples=8)"
      ],
      "metadata": {
        "id": "Gr47U0Cm9YPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature=1):\n",
        "  y_proba = shakespeare_model.predict([text])[0,-1:]\n",
        "  rescaled_logits = tf.math.log(y_proba)/temperature\n",
        "  char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0,0]\n",
        "  return text_vec_layer.get_vocabulary()[char_id+2]"
      ],
      "metadata": {
        "id": "n2nvOQn89jtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extend_text(text, n_chars=100, temperature=1):\n",
        "  for _ in range(n_chars):\n",
        "    text += next_char(text, temperature)\n",
        "  return text"
      ],
      "metadata": {
        "id": "nvRzUVgg-1Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n"
      ],
      "metadata": {
        "id": "Lkgah2Or-9oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extend_text(\"how are you\", temperature=1))"
      ],
      "metadata": {
        "id": "xD0tNtZdAJvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#statwful RNN"
      ],
      "metadata": {
        "id": "gMNmRwA-AeX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset_for_stateful_rnn(sequence, length):\n",
        "  ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "  ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
        "  ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)\n",
        "  return ds.map(lambda window: (window[:,:-1], window[:,1:])).prefetch(1)\n",
        "\n",
        "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length)\n",
        "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000], length)\n",
        "\n",
        "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1_060_000:], length)"
      ],
      "metadata": {
        "id": "yYwBg3qqCSM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(to_dataset_for_stateful_rnn(tf.range(10),3))"
      ],
      "metadata": {
        "id": "KtTuEhofDQv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extra code – shows one way to prepare a batched dataset for a stateful RNN\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def to_non_overlapping_windows(sequence, length):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
        "    return ds.flat_map(lambda window: window.batch(length + 1))\n",
        "\n",
        "def to_batched_dataset_for_stateful_rnn(sequence, length, batch_size=32):\n",
        "    parts = np.array_split(sequence, batch_size)\n",
        "    datasets = tuple(to_non_overlapping_windows(part, length) for part in parts)\n",
        "    ds = tf.data.Dataset.zip(datasets).map(lambda *windows: tf.stack(windows))\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
        "\n",
        "list(to_batched_dataset_for_stateful_rnn(tf.range(20), length=3, batch_size=2))"
      ],
      "metadata": {
        "id": "YCiXkEGhDWsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_begin(self, epoch, logs):\n",
        "    self.model.reset_states()"
      ],
      "metadata": {
        "id": "ftnHNJ5VFrC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model_stateful\", monitor=\"val_accuracy\", save_best_only=True)"
      ],
      "metadata": {
        "id": "3fZnSwZ1F3iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "h2lVUvkRGO_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history =model.fit(stateful_train_set, validation_data=stateful_valid_set, epochs=7, callbacks=[ResetStatesCallback(), model_ckpt])"
      ],
      "metadata": {
        "id": "r2qW0nP3GVxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateless_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "SEW5yHqVHSjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateless_model.build(tf.TensorShape([None, None]))"
      ],
      "metadata": {
        "id": "AcT0nkuvJays"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateless_model.set_weights(model.get_weights())"
      ],
      "metadata": {
        "id": "dUYF4vbFJu3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda X: X-2),\n",
        "    stateless_model\n",
        "])"
      ],
      "metadata": {
        "id": "4VyO0MMHKHKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(extend_text(\"to be or not to be\", temperature=0.01))"
      ],
      "metadata": {
        "id": "nXq-wRSsKsNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOj33_fGLNR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}