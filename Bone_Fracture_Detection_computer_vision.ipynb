{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1LQtytziqxIPW_CjtgbYY1l3kgW4Zc7ls",
      "authorship_tag": "ABX9TyMXfJQ4l3LawA86MJFN34lc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elmir22/Data-science-ML-models-/blob/main/Bone_Fracture_Detection_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "LBFl7Ml-cuco"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LOAn7BGlWJA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9037d642-8088-41d3-f918-c25625dad7f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-13 09:30:47--  https://raw.githubusercontent.com/Rstam59/TaskDataRepoForStudents/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.3’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-13 09:30:47 (68.9 MB/s) - ‘helper_functions.py.3’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Rstam59/TaskDataRepoForStudents/main/helper_functions.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "id": "_9XheZ09bhqI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/archive .zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "kIKKqE4QdbKK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"/content/drive/MyDrive/archive .zip\")"
      ],
      "metadata": {
        "id": "JF9zGBjBbk3l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(\"/content/drive/MyDrive/archive .zip\")"
      ],
      "metadata": {
        "id": "Syw-5m-fbvVm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train\"\n",
        "test_dir = \"/content/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test\""
      ],
      "metadata": {
        "id": "eK1klfYrkIX8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_aug = ImageDataGenerator(rescale=1/255.,\n",
        "                                    rotation_range=0.2,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.0,\n",
        "                                    zoom_range=0.0,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=True)\n",
        "test_data_aug= ImageDataGenerator(rescale=1/255.)"
      ],
      "metadata": {
        "id": "Zs9qV-PDcE7t"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_aug = train_data_aug.flow_from_directory(train_dir,\n",
        "                                               target_size=(224,224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               batch_size=32)\n",
        "test_aug = test_data_aug.flow_from_directory(test_dir,\n",
        "                                             target_size=(224,224),\n",
        "                                             class_mode=\"binary\",\n",
        "                                             batch_size=32)"
      ],
      "metadata": {
        "id": "AKtu7S7HgBOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a612d83-b0f7-4e07-c00b-2cfa15ce2acf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9246 images belonging to 2 classes.\n",
            "Found 506 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(224,224,3)),\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(4,4),\n",
        "                           padding=\"valid\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(4,4),\n",
        "                           padding=\"valid\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(4,4),\n",
        "                           padding=\"valid\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(4,4),\n",
        "                           padding=\"valid\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "QwngfEU1hFkU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "id": "xpw3YaoBUBGh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model_0.compile(loss='binary_crossentropy',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "model_0.fit(train_aug,\n",
        "            epochs=5,\n",
        "            steps_per_epoch=len(train_aug),\n",
        "            validation_data=test_aug,\n",
        "            validation_steps=len(test_aug))\n"
      ],
      "metadata": {
        "id": "ylk-IzLejSJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7c1603-0d37-4172-8d56-a9e131e29ee3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "289/289 [==============================] - 142s 484ms/step - loss: 0.6695 - accuracy: 0.5819 - val_loss: 0.6968 - val_accuracy: 0.5968\n",
            "Epoch 2/5\n",
            "289/289 [==============================] - 143s 494ms/step - loss: 0.6277 - accuracy: 0.6414 - val_loss: 0.7234 - val_accuracy: 0.5968\n",
            "Epoch 3/5\n",
            "289/289 [==============================] - 145s 501ms/step - loss: 0.6085 - accuracy: 0.6616 - val_loss: 0.7767 - val_accuracy: 0.5158\n",
            "Epoch 4/5\n",
            "289/289 [==============================] - 140s 483ms/step - loss: 0.5958 - accuracy: 0.6748 - val_loss: 0.6665 - val_accuracy: 0.6462\n",
            "Epoch 5/5\n",
            "289/289 [==============================] - 143s 494ms/step - loss: 0.5695 - accuracy: 0.7014 - val_loss: 0.6497 - val_accuracy: 0.6917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78cf68036080>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(224,224,3)),\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(4,4),\n",
        "                           padding=\"valid\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(4,4),\n",
        "                           padding=\"valid\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(4,4),\n",
        "                           padding=\"valid\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(4,4),\n",
        "                           padding=\"valid\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "Kx9KZY8jHZte"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "model_1.fit(train_aug,\n",
        "            epochs=5,\n",
        "            steps_per_epoch=len(train_aug),\n",
        "            validation_data=test_aug,\n",
        "            validation_steps=len(test_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WfkEAcHOBQ2",
        "outputId": "d97d5f16-32d3-49da-fe9f-67497cb1775f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "289/289 [==============================] - 152s 508ms/step - loss: 0.6154 - accuracy: 0.6783 - val_loss: 2.1686 - val_accuracy: 0.5296\n",
            "Epoch 2/5\n",
            "289/289 [==============================] - 150s 520ms/step - loss: 0.5747 - accuracy: 0.7274 - val_loss: 1.7339 - val_accuracy: 0.5375\n",
            "Epoch 3/5\n",
            "289/289 [==============================] - 151s 522ms/step - loss: 0.5580 - accuracy: 0.7423 - val_loss: 1.8718 - val_accuracy: 0.5395\n",
            "Epoch 4/5\n",
            "289/289 [==============================] - 147s 509ms/step - loss: 0.5451 - accuracy: 0.7479 - val_loss: 1.7029 - val_accuracy: 0.5138\n",
            "Epoch 5/5\n",
            "289/289 [==============================] - 151s 522ms/step - loss: 0.5282 - accuracy: 0.7604 - val_loss: 1.9313 - val_accuracy: 0.5158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2WpQ_TiXAmd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}